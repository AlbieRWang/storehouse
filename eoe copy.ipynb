{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "metadata": {},
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import os,re,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import pickle\n",
    "import shutil\n",
    "import mutagen\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {},
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "\"BBDown  -M '<videoTitle>#[P<pageNumberWithZero>]#<pageTitle>#<publishDate>#<bvid>' \"\n",
    "\n",
    "data = pd.read_excel('eoe_files.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {},
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "member = ('露早' ,'莞儿', '柚恩', '虞莫','米诺')\n",
    "patt = '|'.join([i[0]+'[^露莞柚虞米]' for  i in member]) + '|[&＆]'\n",
    "def get_members(s):\n",
    "    x = [i for i in member if i[0] in s ]  # 第一个字\n",
    "    if len(x): s = re.sub('EOE\\s?|原$','',s)\n",
    "    if '生贺' in s : s= '生贺'\n",
    "    elif '原创' in s : s = '原创'\n",
    "    x ='&'.join(x)\n",
    "    return x , x + re.sub(patt, '', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkldata = pickle.load(open('录播bilix_info.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "cols = ['bv', 'singer','singer0','song','name', 'is_single','is_sing','ori']\n",
    "data_list = []\n",
    "\n",
    "for name in data.name:\n",
    "    ori = name\n",
    "    name = name.split('#')[0]   \n",
    "    is_single = 1 if 'mp4' in name else 0\n",
    "    name = re.sub('\\[.*mp4$','',name)\n",
    "    bv = re.sub('.mp4$','',ori).split('#')[-1]\n",
    "    bv = np.nan if is_single else bv\n",
    "\n",
    "    if re.findall('[翻合]唱|[团金歌]曲|原[唱创]|混剪',name) : is_sing = 1 \n",
    "    elif re.findall('舞|跳|摇|蹦[蹦迪]',name): is_sing = 2 \n",
    "    else: is_sing = 0\n",
    "        \n",
    "    singer = re.findall('【(.*?)】', re.sub('【EOE一周年】|【新衣特别晚会】','',name))\n",
    "    singer = re.sub('[翻跳唱|丨｜精译]|生日会[_]?|202\\d|组合|一周年' ,'', singer[-1] ) if singer else ''\n",
    "    singer,singer0 = get_members(singer) \n",
    "    if not singer: singer = get_members(name)[0]\n",
    "    if not singer : singer = 'EOE' if re.findall('EOE|合唱|团',name) else ''\n",
    "    song = re.findall('[《『](.*?)[』》]', name)\n",
    "    song = song[0] if song else ''\n",
    "    data_list.append((bv, singer,singer0,song,name, is_single,is_sing,ori))\n",
    "\n",
    "res = pd.DataFrame(data_list, columns= cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "bvs = []\n",
    "cols2 = ['bv', 'name', 'aid', 'ct','desc' ]\n",
    "for bv,bdata in pkldata.items():\n",
    "    bvs.append((bv, bdata.title, bdata.aid, len(bdata.pages) ,bdata.desc))\n",
    "    \n",
    "pkdf = pd.DataFrame(bvs ,columns=cols2)\n",
    "fillbv = pd.merge(res[res.bv.isna()],  pkdf[pkdf.ct==1].reset_index(drop=True) \n",
    "                    ,on = 'name', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "res['name_ori'] = res['name']\n",
    "namask = res.bv.isna()\n",
    "res.loc[namask,'name'] = res.loc[namask,'name'].str.replace('_','')\n",
    "#下载时有下划线?          输出重复的\n",
    "pkdf[pkdf.ct ==1 & pkdf.duplicated('name')].to_excel('duplicate.xlsx')\n",
    "fillbv = pd.merge(res[namask],pkdf[pkdf.ct ==1].drop_duplicates(subset='name').reset_index(drop=True)\n",
    "                  ,on= 'name',how='left')\n",
    "\n",
    "res.loc[namask,'bv'] = fillbv['bv_y'].tolist()  # loc 会按index赋值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "singer_mask = res.singer.str.len() == 0\n",
    "fill_singer = pd.merge(res[singer_mask],pkdf.reset_index(drop=True)\n",
    "                  ,on= 'bv',how='left')\n",
    " \n",
    "def get_members2(s): \n",
    "    x = [i for i in member if i[0] in s ]  # 第一个字 \n",
    "    x ='&'.join(x) if x else '' \n",
    "    if (not x ): x = 'EOE' \n",
    "    return x  \n",
    "\n",
    "fill_singer['sin2'] = fill_singer.desc.fillna('').apply(lambda x : get_members2(  re.findall('.*?[-]{4,}',x ,flags=re.S)[0]  if re.findall('.*?[-]{4,}',x ,flags=re.S) else '' ) )\n",
    "res.loc[singer_mask,'singer'] = fill_singer['sin2'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_excel('res.xlsx') # 检查name重复 bv空的 \n",
    "\n",
    "res = pd.read_excel('res-modify.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "res['folder0'] = res['singer'].apply(lambda x:x if len(x) else '空')\n",
    "sing_map = {0:'创作剪辑',1:'唱',2:'跳'}\n",
    "res['folder1'] = res['is_sing'].map(sing_map)\n",
    "\n",
    "count_map = res.bv.value_counts()\n",
    "res['bvct'] = res.bv.map(count_map)\n",
    "res['file'] = res.ori\n",
    "res.loc[res.bvct == 1, 'ori'] = res.loc[res.bvct == 1, 'name_ori'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "metadata": {},
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "split = res.ori.str.split('#',expand=True).iloc[:,:3]\n",
    "split.columns = ['title','pn','ptitle']\n",
    "res = res.join(split)\n",
    "res.to_excel('res.xlsx',index=None) # 检查 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mid 及歌曲信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  https://api.bilibili.com/x/player/v2?cid=875796755&aid=562069714   #  .data.bgm_info.music_id\n",
    " # https://api.bilibili.com/x/copyright-music-publicity/bgm/detail?music_id=MA407125921754034458\n",
    "import asyncio \n",
    "from bilix.sites.bilibili import api\n",
    "from httpx import AsyncClient\n",
    "\n",
    "async def main(id): \n",
    "    client = AsyncClient(**api.dft_client_settings)\n",
    "    data = await api._get_video_basic_info_from_api(client, f'https://www.bilibili.com/video/{id}') \n",
    "    return data \n",
    "# await main('BV1us421N7aJ')\n",
    "\n",
    "dict_info = {} \n",
    "errbv = []\n",
    "for i,bid  in enumerate( res.bv.unique()):  \n",
    "    try:\n",
    "        info = await main(bid)\n",
    "        print(i,':',bid) \n",
    "    except Exception as e:\n",
    "        errbv.append(bv)\n",
    "        print(i,bv,'获取信息出错',e)\n",
    "        continue \n",
    "    bv,title = info.bvid, info.title\n",
    "    pn = ''\n",
    "    dict_info[bv] = info \n",
    "\n",
    "print(errbv)\n",
    "\n",
    "with open(f'带有cid.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_info, f)   # pkl 存储\n",
    "cidata = pickle.load(open('带有cid.pkl','rb'))\n",
    "\n",
    "bvs = []\n",
    "cols3 = ['bv',  'aid', 'pn', 'cid' ]\n",
    "for bv,bdata in cidata.items(): \n",
    "    cidnfo = []\n",
    "    for p in bdata.pages: \n",
    "        pn = re.findall('\\?p=(\\d+)',p.p_url)\n",
    "        pn = int(pn[0]) if pn else 1\n",
    "        cidnfo.append((bv, bdata.aid, pn, p.pcid))\n",
    "   \n",
    "    bvs.extend(cidnfo) \n",
    "\n",
    "cid_pd = pd.DataFrame(bvs,columns= cols3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res['pn2'] =  res.pn.str.extract('P(\\d+)').fillna(1).astype(int) \n",
    "aid_cid = pd.merge(res, cid_pd , left_on=['bv','pn2'],right_on=['bv','pn'] ,how='left') #.to_excel('test.xlsx') # aid pn_y cid,  \n",
    "aid_cid.aid = aid_cid.aid.fillna(1854252190) # 想你时风起\n",
    "aid_cid.cid = aid_cid.cid.fillna(1538566546) # 1854252190, cid=1538566546\n",
    "url = 'https://api.bilibili.com/x/player/v2?cid=875796755&aid=562069714'   #  .data.bgm_info.music_id\n",
    "# https://api.bilibili.com/x/copyright-music-publicity/bgm/detail?music_id=MA407125921754034458\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_mid(cid, aid):\n",
    "    headers = {'user-agent': 'Mozilla/5.0'}\n",
    "    url = f'https://api.bilibili.com/x/player/v2?cid={cid}&aid={aid}' \n",
    "    mid='' \n",
    "\n",
    "    reqres = requests.get(url, headers=headers) \n",
    "    if reqres.status_code == 200:\n",
    "        data = reqres.json()\n",
    "        mid = data['data'].get('bgm_info')\n",
    "        mid =  mid.get('music_id') if mid else ''\n",
    "        print(cid)\n",
    "    else: \n",
    "        print(f\"Failed to get details for aV: {aid},{cid}\")\n",
    " \n",
    "    return mid\n",
    "\n",
    " \n",
    "# https://api.bilibili.com/x/copyright-music-publicity/bgm/detail?music_id=MA456146494714591308\n",
    "\n",
    "def get_mid_info(mid):\n",
    "    headers = {'user-agent': 'Mozilla/5.0'}\n",
    "    url = f'https://api.bilibili.com/x/copyright-music-publicity/bgm/detail?music_id={mid}'  \n",
    "    info ={}\n",
    "    reqres = requests.get(url, headers=headers) \n",
    "    if reqres.status_code == 200:\n",
    "        data = reqres.json()\n",
    "        info = data['data'] \n",
    "    else: \n",
    "        print(f\"Failed to get details for mid: {mid}\")\n",
    " \n",
    "    return info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mids = []\n",
    "for i in aid_cid.itertuples():\n",
    "    mid = get_mid( int(i.cid) , int(i.aid) )\n",
    "    mids.append(mid)\n",
    "\n",
    "aid_cid['mid'] = mids\n",
    "mid_info = {} \n",
    "m2 = set(mids) \n",
    "m2.remove('') \n",
    " \n",
    "for i,mid in enumerate(m2):\n",
    "    minfo = get_mid_info(mid) \n",
    "    mid_info[mid] = minfo\n",
    "    print(i,mid)\n",
    " \n",
    "with open(f'midinfo.pkl', 'wb') as f:\n",
    "    pickle.dump(mid_info, f)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_df = pd.DataFrame(mid_info).T.reset_index() \n",
    "music_df.drop(columns=['hot_song_heat','ab_test','music_comment'] ,inplace = True)\n",
    "final_merge = pd.merge(aid_cid,  music_df , left_on = 'mid', right_on = 'index', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge.rename(columns = {'pn_x':'pn'} ,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文件部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "oripath = 'origins/'\n",
    "files_path = []\n",
    "from_path = []\n",
    "final_merge.pn = final_merge.pn.fillna('')\n",
    "final_merge.ptitle = final_merge.ptitle.fillna('')\n",
    "\n",
    "for row in final_merge.itertuples():\n",
    "    f0 = 'EOE' if row.folder0.count('&')>1 else row.folder0\n",
    "    files_path.append('/'.join([i for i in \n",
    "                                [f0, row.folder1 , row.title, row.pn + row.ptitle] if i]) +'mp4')\n",
    "    from_path.append( oripath  + row.file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "folders = set(os.path.dirname(p) for p in files_path)\n",
    "for fd in folders:\n",
    "    os.makedirs(fd , exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# final_merge.to_excel('final_merge.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "final_merge['artist'] = final_merge['singer'].str.replace('&','/')\n",
    "final_merge['albumartist'] = final_merge['singer'] + final_merge['is_sing'].map( {0:'创',1:'',2:'舞'} )\n",
    "final_merge['ftitle'] = final_merge.song\n",
    "final_merge.loc[final_merge.song.isna() , 'ftitle'] = final_merge.ptitle[final_merge.song.isna()]\n",
    "final_merge.loc[final_merge.ftitle.isna(), 'ftitle'] = final_merge.loc[final_merge.ftitle.isna(), 'music_title'] \n",
    "#  str.len()对空的不生效!!!  & final_merge.ftitle.str.len()==0  final_merge.song.isna() \n",
    "final_merge.loc[final_merge.ftitle.isna(), 'ftitle'] = final_merge.name[final_merge.ftitle.isna() ] \n",
    "\n",
    "final_merge['origin_artist'].fillna('',inplace=True)\n",
    "final_merge.to_excel('final_merge.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in final_merge.itertuples():\n",
    "    file =  oripath + row.file \n",
    "    mfile = mutagen.File(file, easy=True) \n",
    "\n",
    "    p1 = '' if row.pn2==1 else '?p=' + str(row.pn2)\n",
    "    mfile['comment'] = row.bv + p1\n",
    "    mfile['title'] = row.ftitle\n",
    "    \n",
    "    if row.origin_artist:\n",
    "        mfile['album'] = row.origin_artist\n",
    "        print(file,row.origin_artist)\n",
    "\n",
    "    mfile['albumartist'] = row.albumartist\n",
    "    mfile['artist'] = row.artist\n",
    "    mfile.save(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "metadata": {}
   },
   "source": [
    "#### ffmpeg and move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "opath = oripath  # 'test/'\n",
    "cover_path = opath + 'cover/'\n",
    "audio_path = opath + 'audio/'\n",
    "out_path = opath + 'out/' \n",
    "os.makedirs(cover_path,exist_ok = True)\n",
    "os.makedirs(audio_path,exist_ok = True)\n",
    "os.makedirs(out_path,exist_ok = True)\n",
    "\n",
    "for f in os.listdir( opath ) : # res.file\n",
    "    if '.mp4' not in f: continue \n",
    "    path = opath + f\n",
    "    img  = f.replace('.mp4','.jpg')\n",
    "    m4a  = f.replace('.mp4','.m4a')\n",
    "    imgp = f\"{cover_path}{img}\"\n",
    "    m4ap = f\"{audio_path}{f}\" #m4a\n",
    "    outp = f\"{out_path}{f}\"\n",
    "\n",
    "    # 1st step\n",
    "    # cmd = f'ffmpeg -i \"{path}\"  -map 0:v -map -0:V -c copy \"{imgp}\"  -vn -map_metadata 0 -acodec copy \"{m4ap}\" -y' \n",
    "    # result = subprocess.check_output(cmd).decode('utf-8') \n",
    " \n",
    "    # 压缩后 2nd step\n",
    "    cmd2 = f'ffmpeg -i \"{m4ap}\" -i \"{imgp}\" -c copy -disposition:v attached_pic -map_metadata 0 \"{outp}\" -y' \n",
    "    result2 = subprocess.check_output(cmd2).decode('utf-8') \n",
    "    shutil.move(outp , f\"{out_path}{m4a}\" ) # 阿里分享音频 要mp4改名为m4a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# videos_link[803] # av832691471'  av235210893'\n",
    " #  \"--save-archives-to-file\" }, \"将下载过的视频记录到本地文件中, 用于后续跳过下载同个视频\");\n",
    "#   \"--delay-per-page\" }, \"设置下载合集分P之间的下载间隔时间(单位: 秒, 默认无间隔)\");\n",
    "#  \"--file-pattern\", \"-F\" },  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最后移动\n",
    "for i,fp in enumerate(from_path):\n",
    "    shutil.move(fp , files_path[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 下载多出的(一次)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "add_bvs = pd.read_excel('duplicate-modify.xlsx', sheet_name='Sheet3')\n",
    "# 下载后 文件名字加入有2694个eoe_files.xlsx的后面再进行处理\n",
    "\n",
    "def run_cmd(cmd):\n",
    "# 使用Popen创建进程，并与进程进行复杂的交互\n",
    "    proc = subprocess.Popen(\n",
    "        cmd, # cmd特定的查询空间的命令  'BBDown av1503004887 --audio-only'\n",
    "        stdin=None, # 标准输入 键盘\n",
    "        stdout=subprocess.PIPE, # -1 标准输出（演示器、终端) 保存到管道中以便进行操作\n",
    "        stderr=subprocess.PIPE, # 标准错误，保存到管道\n",
    "        shell=False)       #如果使用 shell=True,则需要在命令字符串中处理引号。 #而 shell=False 时,可以直接在 参数列表 中使用引号表示字符串参数\n",
    "    out, err = proc.communicate() # 获取输出和错误信息\n",
    "    out = out.decode('gbk')\n",
    "    err = err.decode('gbk')\n",
    "    err = '\\n'+err if err else ''\n",
    "    print(f'out:{out[-30:]} {err}') \n",
    "\n",
    " \n",
    "for i,bv  in enumerate(add_bvs['bvs'].tolist()):\n",
    "    cmd =  f\"BBDown {bv} -F <videoTitle>#[P<pageNumberWithZero>]#<pageTitle>#<publishDate>#<bvid>  -M <videoTitle>#[P<pageNumberWithZero>]#<pageTitle>#<publishDate>#<bvid>  -p 1 \"\n",
    "    print(cmd)\n",
    "    # run_cmd(cmd) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  https://api.bilibili.com/x/player/v2?cid=875796755&aid=562069714   #  .data.bgm_info.music_id\n",
    " # https://api.bilibili.com/x/copyright-music-publicity/bgm/detail?music_id=MA407125921754034458\n",
    "import asyncio \n",
    "from bilix.sites.bilibili import api\n",
    "from httpx import AsyncClient\n",
    "\n",
    "async def main(id): \n",
    "    client = AsyncClient(**api.dft_client_settings)\n",
    "    data = await api._get_video_basic_info_from_api(client, f'https://www.bilibili.com/video/{id}') \n",
    "    return data \n",
    "# await main('BV1us421N7aJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_info = {} \n",
    "errbv = []\n",
    "for i,bid  in enumerate( res.bv.unique()):  \n",
    "    try:\n",
    "        info = await main(bid)\n",
    "        print(i,':',bid) \n",
    "    except Exception as e:\n",
    "        errbv.append(bv)\n",
    "        print(i,bv,'获取信息出错',e)\n",
    "        continue \n",
    "    bv,title = info.bvid, info.title\n",
    "    pn = ''\n",
    "    dict_info[bv] = info \n",
    "\n",
    "print(errbv)\n",
    "\n",
    "with open(f'带有cid.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_info, f)   # pkl 存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cidata = pickle.load(open('带有cid.pkl','rb'))\n",
    "\n",
    "bvs = []\n",
    "cols3 = ['bv',  'aid', 'pn', 'cid' ]\n",
    "for bv,bdata in cidata.items(): \n",
    "    cidnfo = []\n",
    "    for p in bdata.pages: \n",
    "        pn = re.findall('\\?p=(\\d+)',p.p_url)\n",
    "        pn = int(pn[0]) if pn else 1\n",
    "        cidnfo.append((bv, bdata.aid, pn, p.pcid))\n",
    "   \n",
    "    bvs.extend(cidnfo) \n",
    "\n",
    "cid_pd = pd.DataFrame(bvs,columns= cols3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['pn2'] =  res.pn.str.extract('P(\\d+)').fillna(1).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "aid_cid = pd.merge(res, cid_pd , left_on=['bv','pn2'],right_on=['bv','pn'] ,how='left') #.to_excel('test.xlsx') # aid pn_y cid,  \n",
    "aid_cid.aid = aid_cid.aid.fillna(1854252190) # 想你时风起\n",
    "aid_cid.cid = aid_cid.cid.fillna(1538566546) # 1854252190, cid=1538566546"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.bilibili.com/x/player/v2?cid=875796755&aid=562069714'   #  .data.bgm_info.music_id\n",
    "# https://api.bilibili.com/x/copyright-music-publicity/bgm/detail?music_id=MA407125921754034458\n",
    "\n",
    "def get_mid(cid, aid):\n",
    "    headers = {'user-agent': 'Mozilla/5.0'}\n",
    "    url = f'https://api.bilibili.com/x/player/v2?cid={cid}&aid={aid}' \n",
    "    mid='' \n",
    "\n",
    "    reqres = requests.get(url, headers=headers) \n",
    "    if reqres.status_code == 200:\n",
    "        data = reqres.json()\n",
    "        mid = data['data'].get('bgm_info')\n",
    "        mid =  mid.get('music_id') if mid else ''\n",
    "        print(cid)\n",
    "    else: \n",
    "        print(f\"Failed to get details for aV: {aid},{cid}\")\n",
    " \n",
    "    return mid\n",
    "\n",
    " \n",
    "# https://api.bilibili.com/x/copyright-music-publicity/bgm/detail?music_id=MA456146494714591308\n",
    "\n",
    "def get_mid_info(mid):\n",
    "    headers = {'user-agent': 'Mozilla/5.0'}\n",
    "    url = f'https://api.bilibili.com/x/copyright-music-publicity/bgm/detail?music_id={mid}'  \n",
    "    info ={}\n",
    "    reqres = requests.get(url, headers=headers) \n",
    "    if reqres.status_code == 200:\n",
    "        data = reqres.json()\n",
    "        info = data['data'] \n",
    "    else: \n",
    "        print(f\"Failed to get details for mid: {mid}\")\n",
    " \n",
    "    return info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mids = []\n",
    "for i in aid_cid.itertuples():\n",
    "    mid = get_mid( int(i.cid) , int(i.aid) )\n",
    "    mids.append(mid)\n",
    "\n",
    "aid_cid['mid'] = mids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_info = {} \n",
    "m2 = set(mids) \n",
    "m2.remove('') \n",
    " \n",
    "for i,mid in enumerate(m2):\n",
    "    minfo = get_mid_info(mid) \n",
    "    mid_info[mid] = minfo\n",
    "    print(i,mid)\n",
    " \n",
    "with open(f'midinfo.pkl', 'wb') as f:\n",
    "    pickle.dump(mid_info, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ item['music_title'] for mid , item in mid_info.items()]\n",
    "music_df = pd.DataFrame(mid_info).T.reset_index() \n",
    "music_df.drop(columns=['hot_song_heat','ab_test','music_comment'] ,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge = pd.merge(aid_cid,  music_df , left_on = 'mid', right_on = 'index', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
